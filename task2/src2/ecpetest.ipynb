{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from container import Container\n",
    "from template import Template, Example\n",
    "api_key = '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'#小陶的apikey\n",
    "model = Container(api_key, 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sb/nbhxgzzj2ds2h3yjxjyn8f2w0000gn/T/ipykernel_70646/90332771.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  five_shot_train = train.loc[train['pairs'].apply(len) == 1].sample(3).append(\n",
      "/var/folders/sb/nbhxgzzj2ds2h3yjxjyn8f2w0000gn/T/ipykernel_70646/90332771.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  five_shot_train = train.loc[train['pairs'].apply(len) == 1].sample(3).append(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dataload import parse_data\n",
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('example.json')\n",
    "one_shot_train = train.loc[train['pairs'].apply(len) == 1].sample(1)\n",
    "five_shot_train = train.loc[train['pairs'].apply(len) == 1].sample(3).append(\n",
    "    train.loc[train['pairs'].apply(len) == 2].sample(1)).append(\n",
    "    train.loc[train['pairs'].apply(len) == 3].sample(1))\n",
    "# ten_shot_train = train.loc[train['pairs'].apply(len) == 1].sample(4).append(\n",
    "#     train.loc[train['pairs'].apply(len) == 2].sample(2)).append(\n",
    "#     train.loc[train['pairs'].apply(len) == 3].sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_train_1 = parse_data(one_shot_train)\n",
    "parse_train_5 = parse_data(five_shot_train)\n",
    "# parse_train_6 = parse_data(ten_shot_train)\n",
    "parse_test = parse_data(test)\n",
    "\n",
    "\n",
    "few_shot = [{'content': e['content'], 'pair': e['pair']} for e in parse_train_5]\n",
    "dev = [{'content': e['content'], 'pair': e['pair']} for e in parse_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Question:\\n', '{$ Question needs answer}'],\n",
       " ['Examples:\\n',\n",
       "  '[{$ Several representative examples of the given question with answers}]'],\n",
       " ['Content:\\n',\n",
       "  '{$ Passage with index which includes the emotion-cause pairs}']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Think step by step. Give a response to the question in this format blew\"\n",
    "question = ['Question:\\n', '{$ Question needs answer}']\n",
    "train = ['Examples:\\n', '[{$ Several representative examples of the given question with answers}]']\n",
    "content = ['Content:\\n', '{$ Passage with index which includes the emotion-cause pairs}']\n",
    "\n",
    "template = Template(instruction=instruction)\n",
    "template(question=question, train=train, content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_temp1 = '''Extract emotion-cause pairs and return a list of tuple based on the given content.\n",
    "In each tuple, the first element is the index of the emotion clause and the second element is the index of cause clause.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_ecpe(model, template, content, temp=0.7, n=2):\n",
    "    train = few_shot[:10]\n",
    "    question = question_temp1\n",
    "    example = Example(question=question, train=train, content=content)\n",
    "    completion, prompt = model.chat(template, example, temp, n)\n",
    "    return completion, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:21<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "prompts = []\n",
    "predict = []\n",
    "result = []\n",
    "for i in tqdm(range(100)):\n",
    "    completion, prompt = few_shot_ecpe(model, template, dev[i]['content'], temp=0.3, n=1)\n",
    "    predict.append(completion.choices[0].text.split(':')[1])\n",
    "    prompts.append(prompt)\n",
    "    result.append(dev[i]['pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_list(data):\n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        predicted = data[i].replace('(', '[').replace(')', ']') #replace all () to []\n",
    "        predicted = predicted.strip() # strip all begining space\n",
    "        predicted = eval(predicted)\n",
    "        result.append(predicted)\n",
    "    return result\n",
    "\n",
    "predict = parse_to_list(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11555555555555555, 0.22608695652173913, 0.15294117647058825, 26, 225, 115)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare(Y1, Y2):\n",
    "    '''Y1: Y_hat case, Y2: Y case'''\n",
    "    correct = 0\n",
    "    for c in Y2:\n",
    "        if c in Y1:\n",
    "            correct += 1\n",
    "    return correct, len(Y1), len(Y2)\n",
    "\n",
    "def calc_precision(Y_hat, Y):\n",
    "    assert len(Y_hat) == len(Y), print('shape mismatched')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    ground_true = 0\n",
    "    for i in range(len(Y_hat)):\n",
    "        c, t, a = compare(Y_hat[i], Y[i])\n",
    "        correct += c\n",
    "        total += t\n",
    "        ground_true += a\n",
    "    precision = correct/total\n",
    "    recall = correct/ground_true\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1, correct, total, ground_true\n",
    "\n",
    "calc_precision(predict, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt_5_shot.txt', 'w') as f:\n",
    "    for sentence in prompts:\n",
    "        f.write(sentence + '---------------End Case---------------\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
